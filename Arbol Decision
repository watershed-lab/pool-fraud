digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label=<X<SUB>4</SUB> &le; 1273.0<br/>entropy = 0.991<br/>samples = 1440<br/>value = [639, 801]<br/>class = VACIA>, fillcolor="#d7ebfa"] ;
1 [label=<X<SUB>4</SUB> &le; 944.0<br/>entropy = 0.452<br/>samples = 443<br/>value = [42, 401]<br/>class = VACIA>, fillcolor="#4ea7e8"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<entropy = 0.0<br/>samples = 225<br/>value = [0, 225]<br/>class = VACIA>, fillcolor="#399de5"] ;
1 -> 2 ;
3 [label=<X<SUB>9</SUB> &le; 2174.0<br/>entropy = 0.707<br/>samples = 218<br/>value = [42, 176]<br/>class = VACIA>, fillcolor="#68b4eb"] ;
1 -> 3 ;
4 [label=<entropy = 0.0<br/>samples = 54<br/>value = [0, 54]<br/>class = VACIA>, fillcolor="#399de5"] ;
3 -> 4 ;
5 [label=<X<SUB>3</SUB> &le; 4609218.5<br/>entropy = 0.821<br/>samples = 164<br/>value = [42, 122]<br/>class = VACIA>, fillcolor="#7dbfee"] ;
3 -> 5 ;
6 [label=<X<SUB>4</SUB> &le; 1206.0<br/>entropy = 0.301<br/>samples = 56<br/>value = [3, 53]<br/>class = VACIA>, fillcolor="#44a3e6"] ;
5 -> 6 ;
7 [label=<entropy = 0.0<br/>samples = 37<br/>value = [0, 37]<br/>class = VACIA>, fillcolor="#399de5"] ;
6 -> 7 ;
8 [label=<X<SUB>4</SUB> &le; 1229.0<br/>entropy = 0.629<br/>samples = 19<br/>value = [3, 16]<br/>class = VACIA>, fillcolor="#5eafea"] ;
6 -> 8 ;
9 [label=<X<SUB>2</SUB> &le; 354462.594<br/>entropy = 0.954<br/>samples = 8<br/>value = [3, 5]<br/>class = VACIA>, fillcolor="#b0d8f5"] ;
8 -> 9 ;
10 [label=<X<SUB>9</SUB> &le; 2339.0<br/>entropy = 0.65<br/>samples = 6<br/>value = [1, 5]<br/>class = VACIA>, fillcolor="#61b1ea"] ;
9 -> 10 ;
11 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
10 -> 11 ;
12 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = VACIA>, fillcolor="#399de5"] ;
10 -> 12 ;
13 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
9 -> 13 ;
14 [label=<entropy = 0.0<br/>samples = 11<br/>value = [0, 11]<br/>class = VACIA>, fillcolor="#399de5"] ;
8 -> 14 ;
15 [label=<X<SUB>7</SUB> &le; 1466.0<br/>entropy = 0.944<br/>samples = 108<br/>value = [39, 69]<br/>class = VACIA>, fillcolor="#a9d4f4"] ;
5 -> 15 ;
16 [label=<X<SUB>14</SUB> &le; 8320200448.0<br/>entropy = 0.985<br/>samples = 49<br/>value = [28, 21]<br/>class = LLENA>, fillcolor="#f8e0ce"] ;
15 -> 16 ;
17 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = VACIA>, fillcolor="#399de5"] ;
16 -> 17 ;
18 [label=<X<SUB>2</SUB> &le; 357186.547<br/>entropy = 0.956<br/>samples = 45<br/>value = [28, 17]<br/>class = LLENA>, fillcolor="#f5ceb1"] ;
16 -> 18 ;
19 [label=<X<SUB>13</SUB> &le; 1293.0<br/>entropy = 0.852<br/>samples = 36<br/>value = [26, 10]<br/>class = LLENA>, fillcolor="#efb185"] ;
18 -> 19 ;
20 [label=<X<SUB>12</SUB> &le; 2123.0<br/>entropy = 0.961<br/>samples = 26<br/>value = [16, 10]<br/>class = LLENA>, fillcolor="#f5d0b5"] ;
19 -> 20 ;
21 [label=<X<SUB>7</SUB> &le; 1390.0<br/>entropy = 0.887<br/>samples = 23<br/>value = [16, 7]<br/>class = LLENA>, fillcolor="#f0b890"] ;
20 -> 21 ;
22 [label=<entropy = 0.792<br/>samples = 21<br/>value = [16, 5]<br/>class = LLENA>, fillcolor="#eda877"] ;
21 -> 22 ;
23 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = VACIA>, fillcolor="#399de5"] ;
21 -> 23 ;
24 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = VACIA>, fillcolor="#399de5"] ;
20 -> 24 ;
25 [label=<entropy = 0.0<br/>samples = 10<br/>value = [10, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
19 -> 25 ;
26 [label=<X<SUB>8</SUB> &le; 2576.5<br/>entropy = 0.764<br/>samples = 9<br/>value = [2, 7]<br/>class = VACIA>, fillcolor="#72b9ec"] ;
18 -> 26 ;
27 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 7]<br/>class = VACIA>, fillcolor="#399de5"] ;
26 -> 27 ;
28 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
26 -> 28 ;
29 [label=<X<SUB>13</SUB> &le; 2719.5<br/>entropy = 0.694<br/>samples = 59<br/>value = [11, 48]<br/>class = VACIA>, fillcolor="#66b3eb"] ;
15 -> 29 ;
30 [label=<X<SUB>6</SUB> &le; 1368.0<br/>entropy = 0.629<br/>samples = 57<br/>value = [9, 48]<br/>class = VACIA>, fillcolor="#5eafea"] ;
29 -> 30 ;
31 [label=<X<SUB>7</SUB> &le; 1871.0<br/>entropy = 0.8<br/>samples = 37<br/>value = [9, 28]<br/>class = VACIA>, fillcolor="#79bced"] ;
30 -> 31 ;
32 [label=<X<SUB>8</SUB> &le; 2392.0<br/>entropy = 0.48<br/>samples = 29<br/>value = [3, 26]<br/>class = VACIA>, fillcolor="#50a8e8"] ;
31 -> 32 ;
33 [label=<X<SUB>9</SUB> &le; 2621.5<br/>entropy = 0.811<br/>samples = 12<br/>value = [3, 9]<br/>class = VACIA>, fillcolor="#7bbeee"] ;
32 -> 33 ;
34 [label=<entropy = 0.0<br/>samples = 8<br/>value = [0, 8]<br/>class = VACIA>, fillcolor="#399de5"] ;
33 -> 34 ;
35 [label=<entropy = 0.811<br/>samples = 4<br/>value = [3, 1]<br/>class = LLENA>, fillcolor="#eeab7b"] ;
33 -> 35 ;
36 [label=<entropy = 0.0<br/>samples = 17<br/>value = [0, 17]<br/>class = VACIA>, fillcolor="#399de5"] ;
32 -> 36 ;
37 [label=<X<SUB>10</SUB> &le; 2941.0<br/>entropy = 0.811<br/>samples = 8<br/>value = [6, 2]<br/>class = LLENA>, fillcolor="#eeab7b"] ;
31 -> 37 ;
38 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = VACIA>, fillcolor="#399de5"] ;
37 -> 38 ;
39 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
37 -> 39 ;
40 [label=<entropy = 0.0<br/>samples = 20<br/>value = [0, 20]<br/>class = VACIA>, fillcolor="#399de5"] ;
30 -> 40 ;
41 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
29 -> 41 ;
42 [label=<X<SUB>4</SUB> &le; 1607.5<br/>entropy = 0.972<br/>samples = 997<br/>value = [597, 400]<br/>class = LLENA>, fillcolor="#f6d5be"] ;
0 -> 42 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
43 [label=<X<SUB>6</SUB> &le; 1597.0<br/>entropy = 0.968<br/>samples = 317<br/>value = [125, 192]<br/>class = VACIA>, fillcolor="#baddf6"] ;
42 -> 43 ;
44 [label=<X<SUB>11</SUB> &le; 2447.0<br/>entropy = 0.998<br/>samples = 242<br/>value = [115, 127]<br/>class = VACIA>, fillcolor="#ecf6fd"] ;
43 -> 44 ;
45 [label=<X<SUB>2</SUB> &le; 353228.328<br/>entropy = 0.601<br/>samples = 41<br/>value = [6, 35]<br/>class = VACIA>, fillcolor="#5baee9"] ;
44 -> 45 ;
46 [label=<X<SUB>4</SUB> &le; 1371.5<br/>entropy = 0.985<br/>samples = 7<br/>value = [4, 3]<br/>class = LLENA>, fillcolor="#f8e0ce"] ;
45 -> 46 ;
47 [label=<X<SUB>14</SUB> &le; 4720200576.0<br/>entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = VACIA>, fillcolor="#7bbeee"] ;
46 -> 47 ;
48 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
47 -> 48 ;
49 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = VACIA>, fillcolor="#399de5"] ;
47 -> 49 ;
50 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
46 -> 50 ;
51 [label=<X<SUB>1</SUB> &le; 244.71<br/>entropy = 0.323<br/>samples = 34<br/>value = [2, 32]<br/>class = VACIA>, fillcolor="#45a3e7"] ;
45 -> 51 ;
52 [label=<entropy = 0.0<br/>samples = 29<br/>value = [0, 29]<br/>class = VACIA>, fillcolor="#399de5"] ;
51 -> 52 ;
53 [label=<X<SUB>4</SUB> &le; 1422.0<br/>entropy = 0.971<br/>samples = 5<br/>value = [2, 3]<br/>class = VACIA>, fillcolor="#bddef6"] ;
51 -> 53 ;
54 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = VACIA>, fillcolor="#399de5"] ;
53 -> 54 ;
55 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
53 -> 55 ;
56 [label=<X<SUB>5</SUB> &le; 1299.5<br/>entropy = 0.995<br/>samples = 201<br/>value = [109, 92]<br/>class = LLENA>, fillcolor="#fbebe0"] ;
44 -> 56 ;
57 [label=<X<SUB>4</SUB> &le; 1373.5<br/>entropy = 0.775<br/>samples = 57<br/>value = [44, 13]<br/>class = LLENA>, fillcolor="#eda674"] ;
56 -> 57 ;
58 [label=<X<SUB>3</SUB> &le; 4609290.75<br/>entropy = 0.963<br/>samples = 31<br/>value = [19, 12]<br/>class = LLENA>, fillcolor="#f5d1b6"] ;
57 -> 58 ;
59 [label=<X<SUB>9</SUB> &le; 2496.5<br/>entropy = 0.779<br/>samples = 13<br/>value = [3, 10]<br/>class = VACIA>, fillcolor="#74baed"] ;
58 -> 59 ;
60 [label=<X<SUB>8</SUB> &le; 2022.5<br/>entropy = 0.985<br/>samples = 7<br/>value = [3, 4]<br/>class = VACIA>, fillcolor="#cee6f8"] ;
59 -> 60 ;
61 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = VACIA>, fillcolor="#399de5"] ;
60 -> 61 ;
62 [label=<X<SUB>0</SUB> &le; 518.0<br/>entropy = 0.811<br/>samples = 4<br/>value = [3, 1]<br/>class = LLENA>, fillcolor="#eeab7b"] ;
60 -> 62 ;
63 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
62 -> 63 ;
64 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
62 -> 64 ;
65 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 6]<br/>class = VACIA>, fillcolor="#399de5"] ;
59 -> 65 ;
66 [label=<X<SUB>7</SUB> &le; 1808.5<br/>entropy = 0.503<br/>samples = 18<br/>value = [16, 2]<br/>class = LLENA>, fillcolor="#e89152"] ;
58 -> 66 ;
67 [label=<entropy = 0.0<br/>samples = 14<br/>value = [14, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
66 -> 67 ;
68 [label=<X<SUB>5</SUB> &le; 1290.0<br/>entropy = 1.0<br/>samples = 4<br/>value = [2, 2]<br/>class = LLENA>, fillcolor="#ffffff"] ;
66 -> 68 ;
69 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = VACIA>, fillcolor="#399de5"] ;
68 -> 69 ;
70 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
68 -> 70 ;
71 [label=<X<SUB>1</SUB> &le; 293.91<br/>entropy = 0.235<br/>samples = 26<br/>value = [25, 1]<br/>class = LLENA>, fillcolor="#e68641"] ;
57 -> 71 ;
72 [label=<entropy = 0.0<br/>samples = 25<br/>value = [25, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
71 -> 72 ;
73 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
71 -> 73 ;
74 [label=<X<SUB>3</SUB> &le; 4609532.5<br/>entropy = 0.993<br/>samples = 144<br/>value = [65, 79]<br/>class = VACIA>, fillcolor="#dceefa"] ;
56 -> 74 ;
75 [label=<X<SUB>10</SUB> &le; 2132.0<br/>entropy = 0.851<br/>samples = 65<br/>value = [18, 47]<br/>class = VACIA>, fillcolor="#85c3ef"] ;
74 -> 75 ;
76 [label=<entropy = 0.0<br/>samples = 9<br/>value = [0, 9]<br/>class = VACIA>, fillcolor="#399de5"] ;
75 -> 76 ;
77 [label=<X<SUB>10</SUB> &le; 2997.5<br/>entropy = 0.906<br/>samples = 56<br/>value = [18, 38]<br/>class = VACIA>, fillcolor="#97cbf1"] ;
75 -> 77 ;
78 [label=<X<SUB>0</SUB> &le; 440.0<br/>entropy = 0.995<br/>samples = 35<br/>value = [16, 19]<br/>class = VACIA>, fillcolor="#e0f0fb"] ;
77 -> 78 ;
79 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
78 -> 79 ;
80 [label=<X<SUB>12</SUB> &le; 2245.5<br/>entropy = 0.929<br/>samples = 29<br/>value = [10, 19]<br/>class = VACIA>, fillcolor="#a1d1f3"] ;
78 -> 80 ;
81 [label=<entropy = 0.391<br/>samples = 13<br/>value = [1, 12]<br/>class = VACIA>, fillcolor="#49a5e7"] ;
80 -> 81 ;
82 [label=<entropy = 0.989<br/>samples = 16<br/>value = [9, 7]<br/>class = LLENA>, fillcolor="#f9e3d3"] ;
80 -> 82 ;
83 [label=<X<SUB>7</SUB> &le; 1934.5<br/>entropy = 0.454<br/>samples = 21<br/>value = [2, 19]<br/>class = VACIA>, fillcolor="#4ea7e8"] ;
77 -> 83 ;
84 [label=<entropy = 0.0<br/>samples = 16<br/>value = [0, 16]<br/>class = VACIA>, fillcolor="#399de5"] ;
83 -> 84 ;
85 [label=<X<SUB>13</SUB> &le; 2163.5<br/>entropy = 0.971<br/>samples = 5<br/>value = [2, 3]<br/>class = VACIA>, fillcolor="#bddef6"] ;
83 -> 85 ;
86 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
85 -> 86 ;
87 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = VACIA>, fillcolor="#399de5"] ;
85 -> 87 ;
88 [label=<X<SUB>11</SUB> &le; 3250.5<br/>entropy = 0.974<br/>samples = 79<br/>value = [47, 32]<br/>class = LLENA>, fillcolor="#f7d7c0"] ;
74 -> 88 ;
89 [label=<X<SUB>14</SUB> &le; 1070200960.0<br/>entropy = 0.998<br/>samples = 55<br/>value = [26, 29]<br/>class = VACIA>, fillcolor="#ebf5fc"] ;
88 -> 89 ;
90 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 6]<br/>class = VACIA>, fillcolor="#399de5"] ;
89 -> 90 ;
91 [label=<X<SUB>2</SUB> &le; 352569.062<br/>entropy = 0.997<br/>samples = 49<br/>value = [26, 23]<br/>class = LLENA>, fillcolor="#fcf0e8"] ;
89 -> 91 ;
92 [label=<entropy = 0.0<br/>samples = 5<br/>value = [5, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
91 -> 92 ;
93 [label=<X<SUB>8</SUB> &le; 2177.0<br/>entropy = 0.999<br/>samples = 44<br/>value = [21, 23]<br/>class = VACIA>, fillcolor="#eef6fd"] ;
91 -> 93 ;
94 [label=<entropy = 0.684<br/>samples = 11<br/>value = [9, 2]<br/>class = LLENA>, fillcolor="#eb9d65"] ;
93 -> 94 ;
95 [label=<entropy = 0.946<br/>samples = 33<br/>value = [12, 21]<br/>class = VACIA>, fillcolor="#aad5f4"] ;
93 -> 95 ;
96 [label=<X<SUB>11</SUB> &le; 3545.5<br/>entropy = 0.544<br/>samples = 24<br/>value = [21, 3]<br/>class = LLENA>, fillcolor="#e99355"] ;
88 -> 96 ;
97 [label=<entropy = 0.0<br/>samples = 14<br/>value = [14, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
96 -> 97 ;
98 [label=<X<SUB>6</SUB> &le; 1184.0<br/>entropy = 0.881<br/>samples = 10<br/>value = [7, 3]<br/>class = LLENA>, fillcolor="#f0b78e"] ;
96 -> 98 ;
99 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = VACIA>, fillcolor="#399de5"] ;
98 -> 99 ;
100 [label=<X<SUB>13</SUB> &le; 1707.5<br/>entropy = 0.544<br/>samples = 8<br/>value = [7, 1]<br/>class = LLENA>, fillcolor="#e99355"] ;
98 -> 100 ;
101 [label=<entropy = 0.0<br/>samples = 7<br/>value = [7, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
100 -> 101 ;
102 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
100 -> 102 ;
103 [label=<X<SUB>3</SUB> &le; 4615314.25<br/>entropy = 0.567<br/>samples = 75<br/>value = [10, 65]<br/>class = VACIA>, fillcolor="#57ace9"] ;
43 -> 103 ;
104 [label=<X<SUB>4</SUB> &le; 1505.5<br/>entropy = 0.375<br/>samples = 69<br/>value = [5, 64]<br/>class = VACIA>, fillcolor="#48a5e7"] ;
103 -> 104 ;
105 [label=<entropy = 0.0<br/>samples = 32<br/>value = [0, 32]<br/>class = VACIA>, fillcolor="#399de5"] ;
104 -> 105 ;
106 [label=<X<SUB>2</SUB> &le; 354476.422<br/>entropy = 0.571<br/>samples = 37<br/>value = [5, 32]<br/>class = VACIA>, fillcolor="#58ace9"] ;
104 -> 106 ;
107 [label=<X<SUB>1</SUB> &le; 130.73<br/>entropy = 0.831<br/>samples = 19<br/>value = [5, 14]<br/>class = VACIA>, fillcolor="#80c0ee"] ;
106 -> 107 ;
108 [label=<X<SUB>7</SUB> &le; 2017.5<br/>entropy = 1.0<br/>samples = 10<br/>value = [5, 5]<br/>class = LLENA>, fillcolor="#ffffff"] ;
107 -> 108 ;
109 [label=<X<SUB>13</SUB> &le; 2425.0<br/>entropy = 0.65<br/>samples = 6<br/>value = [1, 5]<br/>class = VACIA>, fillcolor="#61b1ea"] ;
108 -> 109 ;
110 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = VACIA>, fillcolor="#399de5"] ;
109 -> 110 ;
111 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
109 -> 111 ;
112 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
108 -> 112 ;
113 [label=<entropy = 0.0<br/>samples = 9<br/>value = [0, 9]<br/>class = VACIA>, fillcolor="#399de5"] ;
107 -> 113 ;
114 [label=<entropy = 0.0<br/>samples = 18<br/>value = [0, 18]<br/>class = VACIA>, fillcolor="#399de5"] ;
106 -> 114 ;
115 [label=<X<SUB>12</SUB> &le; 2190.0<br/>entropy = 0.65<br/>samples = 6<br/>value = [5, 1]<br/>class = LLENA>, fillcolor="#ea9a61"] ;
103 -> 115 ;
116 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
115 -> 116 ;
117 [label=<entropy = 0.0<br/>samples = 5<br/>value = [5, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
115 -> 117 ;
118 [label=<X<SUB>6</SUB> &le; 1929.5<br/>entropy = 0.888<br/>samples = 680<br/>value = [472, 208]<br/>class = LLENA>, fillcolor="#f0b990"] ;
42 -> 118 ;
119 [label=<X<SUB>4</SUB> &le; 1967.5<br/>entropy = 0.673<br/>samples = 407<br/>value = [335, 72]<br/>class = LLENA>, fillcolor="#eb9c64"] ;
118 -> 119 ;
120 [label=<X<SUB>6</SUB> &le; 1194.5<br/>entropy = 0.875<br/>samples = 210<br/>value = [148, 62]<br/>class = LLENA>, fillcolor="#f0b68c"] ;
119 -> 120 ;
121 [label=<entropy = 0.0<br/>samples = 26<br/>value = [26, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
120 -> 121 ;
122 [label=<X<SUB>8</SUB> &le; 2044.5<br/>entropy = 0.922<br/>samples = 184<br/>value = [122, 62]<br/>class = LLENA>, fillcolor="#f2c19e"] ;
120 -> 122 ;
123 [label=<X<SUB>2</SUB> &le; 353862.969<br/>entropy = 0.696<br/>samples = 16<br/>value = [3, 13]<br/>class = VACIA>, fillcolor="#67b4eb"] ;
122 -> 123 ;
124 [label=<entropy = 0.0<br/>samples = 9<br/>value = [0, 9]<br/>class = VACIA>, fillcolor="#399de5"] ;
123 -> 124 ;
125 [label=<X<SUB>7</SUB> &le; 1614.5<br/>entropy = 0.985<br/>samples = 7<br/>value = [3, 4]<br/>class = VACIA>, fillcolor="#cee6f8"] ;
123 -> 125 ;
126 [label=<X<SUB>8</SUB> &le; 1703.0<br/>entropy = 0.811<br/>samples = 4<br/>value = [3, 1]<br/>class = LLENA>, fillcolor="#eeab7b"] ;
125 -> 126 ;
127 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
126 -> 127 ;
128 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
126 -> 128 ;
129 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = VACIA>, fillcolor="#399de5"] ;
125 -> 129 ;
130 [label=<X<SUB>5</SUB> &le; 1906.5<br/>entropy = 0.871<br/>samples = 168<br/>value = [119, 49]<br/>class = LLENA>, fillcolor="#f0b58b"] ;
122 -> 130 ;
131 [label=<X<SUB>8</SUB> &le; 2155.0<br/>entropy = 0.83<br/>samples = 160<br/>value = [118, 42]<br/>class = LLENA>, fillcolor="#eeae7f"] ;
130 -> 131 ;
132 [label=<entropy = 0.0<br/>samples = 14<br/>value = [14, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
131 -> 132 ;
133 [label=<X<SUB>11</SUB> &le; 2795.5<br/>entropy = 0.866<br/>samples = 146<br/>value = [104, 42]<br/>class = LLENA>, fillcolor="#f0b489"] ;
131 -> 133 ;
134 [label=<X<SUB>8</SUB> &le; 2419.5<br/>entropy = 1.0<br/>samples = 30<br/>value = [15, 15]<br/>class = LLENA>, fillcolor="#ffffff"] ;
133 -> 134 ;
135 [label=<entropy = 0.983<br/>samples = 26<br/>value = [11, 15]<br/>class = VACIA>, fillcolor="#cae5f8"] ;
134 -> 135 ;
136 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
134 -> 136 ;
137 [label=<X<SUB>2</SUB> &le; 354579.672<br/>entropy = 0.783<br/>samples = 116<br/>value = [89, 27]<br/>class = LLENA>, fillcolor="#eda775"] ;
133 -> 137 ;
138 [label=<entropy = 0.592<br/>samples = 70<br/>value = [60, 10]<br/>class = LLENA>, fillcolor="#e9965a"] ;
137 -> 138 ;
139 [label=<entropy = 0.95<br/>samples = 46<br/>value = [29, 17]<br/>class = LLENA>, fillcolor="#f4cbad"] ;
137 -> 139 ;
140 [label=<X<SUB>10</SUB> &le; 2063.5<br/>entropy = 0.544<br/>samples = 8<br/>value = [1, 7]<br/>class = VACIA>, fillcolor="#55abe9"] ;
130 -> 140 ;
141 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
140 -> 141 ;
142 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 7]<br/>class = VACIA>, fillcolor="#399de5"] ;
140 -> 142 ;
143 [label=<X<SUB>4</SUB> &le; 2327.5<br/>entropy = 0.29<br/>samples = 197<br/>value = [187, 10]<br/>class = LLENA>, fillcolor="#e68844"] ;
119 -> 143 ;
144 [label=<X<SUB>4</SUB> &le; 2323.0<br/>entropy = 0.387<br/>samples = 132<br/>value = [122, 10]<br/>class = LLENA>, fillcolor="#e78b49"] ;
143 -> 144 ;
145 [label=<X<SUB>6</SUB> &le; 1565.0<br/>entropy = 0.334<br/>samples = 130<br/>value = [122, 8]<br/>class = LLENA>, fillcolor="#e78946"] ;
144 -> 145 ;
146 [label=<X<SUB>13</SUB> &le; 1112.0<br/>entropy = 0.101<br/>samples = 76<br/>value = [75, 1]<br/>class = LLENA>, fillcolor="#e5833c"] ;
145 -> 146 ;
147 [label=<X<SUB>2</SUB> &le; 355869.594<br/>entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = LLENA>, fillcolor="#eca06a"] ;
146 -> 147 ;
148 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
147 -> 148 ;
149 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
147 -> 149 ;
150 [label=<entropy = 0.0<br/>samples = 71<br/>value = [71, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
146 -> 150 ;
151 [label=<X<SUB>7</SUB> &le; 2038.0<br/>entropy = 0.556<br/>samples = 54<br/>value = [47, 7]<br/>class = LLENA>, fillcolor="#e99456"] ;
145 -> 151 ;
152 [label=<X<SUB>1</SUB> &le; 84.875<br/>entropy = 0.758<br/>samples = 32<br/>value = [25, 7]<br/>class = LLENA>, fillcolor="#eca470"] ;
151 -> 152 ;
153 [label=<entropy = 0.0<br/>samples = 9<br/>value = [9, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
152 -> 153 ;
154 [label=<X<SUB>11</SUB> &le; 3069.0<br/>entropy = 0.887<br/>samples = 23<br/>value = [16, 7]<br/>class = LLENA>, fillcolor="#f0b890"] ;
152 -> 154 ;
155 [label=<entropy = 0.544<br/>samples = 16<br/>value = [14, 2]<br/>class = LLENA>, fillcolor="#e99355"] ;
154 -> 155 ;
156 [label=<entropy = 0.863<br/>samples = 7<br/>value = [2, 5]<br/>class = VACIA>, fillcolor="#88c4ef"] ;
154 -> 156 ;
157 [label=<entropy = 0.0<br/>samples = 22<br/>value = [22, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
151 -> 157 ;
158 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = VACIA>, fillcolor="#399de5"] ;
144 -> 158 ;
159 [label=<entropy = 0.0<br/>samples = 65<br/>value = [65, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
143 -> 159 ;
160 [label=<X<SUB>7</SUB> &le; 2949.0<br/>entropy = 1.0<br/>samples = 273<br/>value = [137, 136]<br/>class = LLENA>, fillcolor="#fffefe"] ;
118 -> 160 ;
161 [label=<X<SUB>4</SUB> &le; 2289.5<br/>entropy = 0.992<br/>samples = 245<br/>value = [135, 110]<br/>class = LLENA>, fillcolor="#fae8da"] ;
160 -> 161 ;
162 [label=<X<SUB>5</SUB> &le; 2194.5<br/>entropy = 0.966<br/>samples = 130<br/>value = [51, 79]<br/>class = VACIA>, fillcolor="#b9dcf6"] ;
161 -> 162 ;
163 [label=<X<SUB>2</SUB> &le; 353224.297<br/>entropy = 0.999<br/>samples = 100<br/>value = [48, 52]<br/>class = VACIA>, fillcolor="#f0f7fd"] ;
162 -> 163 ;
164 [label=<X<SUB>7</SUB> &le; 2271.5<br/>entropy = 0.371<br/>samples = 14<br/>value = [13, 1]<br/>class = LLENA>, fillcolor="#e78b48"] ;
163 -> 164 ;
165 [label=<entropy = 0.0<br/>samples = 11<br/>value = [11, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
164 -> 165 ;
166 [label=<X<SUB>13</SUB> &le; 2260.0<br/>entropy = 0.918<br/>samples = 3<br/>value = [2, 1]<br/>class = LLENA>, fillcolor="#f2c09c"] ;
164 -> 166 ;
167 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
166 -> 167 ;
168 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
166 -> 168 ;
169 [label=<X<SUB>4</SUB> &le; 2002.5<br/>entropy = 0.975<br/>samples = 86<br/>value = [35, 51]<br/>class = VACIA>, fillcolor="#c1e0f7"] ;
163 -> 169 ;
170 [label=<X<SUB>11</SUB> &le; 2626.5<br/>entropy = 0.828<br/>samples = 46<br/>value = [12, 34]<br/>class = VACIA>, fillcolor="#7fc0ee"] ;
169 -> 170 ;
171 [label=<entropy = 0.0<br/>samples = 11<br/>value = [0, 11]<br/>class = VACIA>, fillcolor="#399de5"] ;
170 -> 171 ;
172 [label=<X<SUB>8</SUB> &le; 2884.5<br/>entropy = 0.928<br/>samples = 35<br/>value = [12, 23]<br/>class = VACIA>, fillcolor="#a0d0f3"] ;
170 -> 172 ;
173 [label=<entropy = 0.985<br/>samples = 28<br/>value = [12, 16]<br/>class = VACIA>, fillcolor="#cee6f8"] ;
172 -> 173 ;
174 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 7]<br/>class = VACIA>, fillcolor="#399de5"] ;
172 -> 174 ;
175 [label=<X<SUB>1</SUB> &le; 149.605<br/>entropy = 0.984<br/>samples = 40<br/>value = [23, 17]<br/>class = LLENA>, fillcolor="#f8decb"] ;
169 -> 175 ;
176 [label=<X<SUB>8</SUB> &le; 2375.0<br/>entropy = 0.999<br/>samples = 31<br/>value = [15, 16]<br/>class = VACIA>, fillcolor="#f3f9fd"] ;
175 -> 176 ;
177 [label=<entropy = 0.544<br/>samples = 8<br/>value = [1, 7]<br/>class = VACIA>, fillcolor="#55abe9"] ;
176 -> 177 ;
178 [label=<entropy = 0.966<br/>samples = 23<br/>value = [14, 9]<br/>class = LLENA>, fillcolor="#f6d2b8"] ;
176 -> 178 ;
179 [label=<X<SUB>4</SUB> &le; 2257.0<br/>entropy = 0.503<br/>samples = 9<br/>value = [8, 1]<br/>class = LLENA>, fillcolor="#e89152"] ;
175 -> 179 ;
180 [label=<entropy = 0.0<br/>samples = 8<br/>value = [8, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
179 -> 180 ;
181 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = VACIA>, fillcolor="#399de5"] ;
179 -> 181 ;
182 [label=<X<SUB>12</SUB> &le; 3500.5<br/>entropy = 0.469<br/>samples = 30<br/>value = [3, 27]<br/>class = VACIA>, fillcolor="#4fa8e8"] ;
162 -> 182 ;
183 [label=<X<SUB>3</SUB> &le; 4608075.5<br/>entropy = 0.222<br/>samples = 28<br/>value = [1, 27]<br/>class = VACIA>, fillcolor="#40a1e6"] ;
182 -> 183 ;
184 [label=<X<SUB>13</SUB> &le; 1739.0<br/>entropy = 0.722<br/>samples = 5<br/>value = [1, 4]<br/>class = VACIA>, fillcolor="#6ab6ec"] ;
183 -> 184 ;
185 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = VACIA>, fillcolor="#399de5"] ;
184 -> 185 ;
186 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
184 -> 186 ;
187 [label=<entropy = 0.0<br/>samples = 23<br/>value = [0, 23]<br/>class = VACIA>, fillcolor="#399de5"] ;
183 -> 187 ;
188 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
182 -> 188 ;
189 [label=<X<SUB>13</SUB> &le; 1919.5<br/>entropy = 0.841<br/>samples = 115<br/>value = [84, 31]<br/>class = LLENA>, fillcolor="#efb082"] ;
161 -> 189 ;
190 [label=<X<SUB>6</SUB> &le; 2468.5<br/>entropy = 0.281<br/>samples = 41<br/>value = [39, 2]<br/>class = LLENA>, fillcolor="#e68743"] ;
189 -> 190 ;
191 [label=<entropy = 0.0<br/>samples = 28<br/>value = [28, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
190 -> 191 ;
192 [label=<X<SUB>12</SUB> &le; 2490.5<br/>entropy = 0.619<br/>samples = 13<br/>value = [11, 2]<br/>class = LLENA>, fillcolor="#ea985d"] ;
190 -> 192 ;
193 [label=<entropy = 0.0<br/>samples = 8<br/>value = [8, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
192 -> 193 ;
194 [label=<X<SUB>12</SUB> &le; 2589.0<br/>entropy = 0.971<br/>samples = 5<br/>value = [3, 2]<br/>class = LLENA>, fillcolor="#f6d5bd"] ;
192 -> 194 ;
195 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = VACIA>, fillcolor="#399de5"] ;
194 -> 195 ;
196 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
194 -> 196 ;
197 [label=<X<SUB>9</SUB> &le; 2848.0<br/>entropy = 0.966<br/>samples = 74<br/>value = [45, 29]<br/>class = LLENA>, fillcolor="#f6d2b9"] ;
189 -> 197 ;
198 [label=<X<SUB>7</SUB> &le; 2122.0<br/>entropy = 0.902<br/>samples = 22<br/>value = [7, 15]<br/>class = VACIA>, fillcolor="#95cbf1"] ;
197 -> 198 ;
199 [label=<X<SUB>4</SUB> &le; 2608.0<br/>entropy = 0.996<br/>samples = 13<br/>value = [7, 6]<br/>class = LLENA>, fillcolor="#fbede3"] ;
198 -> 199 ;
200 [label=<X<SUB>5</SUB> &le; 1958.5<br/>entropy = 0.592<br/>samples = 7<br/>value = [1, 6]<br/>class = VACIA>, fillcolor="#5aade9"] ;
199 -> 200 ;
201 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
200 -> 201 ;
202 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 6]<br/>class = VACIA>, fillcolor="#399de5"] ;
200 -> 202 ;
203 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
199 -> 203 ;
204 [label=<entropy = 0.0<br/>samples = 9<br/>value = [0, 9]<br/>class = VACIA>, fillcolor="#399de5"] ;
198 -> 204 ;
205 [label=<X<SUB>10</SUB> &le; 2622.0<br/>entropy = 0.84<br/>samples = 52<br/>value = [38, 14]<br/>class = LLENA>, fillcolor="#efaf82"] ;
197 -> 205 ;
206 [label=<entropy = 0.0<br/>samples = 10<br/>value = [10, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
205 -> 206 ;
207 [label=<X<SUB>2</SUB> &le; 353875.297<br/>entropy = 0.918<br/>samples = 42<br/>value = [28, 14]<br/>class = LLENA>, fillcolor="#f2c09c"] ;
205 -> 207 ;
208 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
207 -> 208 ;
209 [label=<X<SUB>13</SUB> &le; 2192.5<br/>entropy = 0.964<br/>samples = 36<br/>value = [22, 14]<br/>class = LLENA>, fillcolor="#f6d1b7"] ;
207 -> 209 ;
210 [label=<entropy = 0.828<br/>samples = 23<br/>value = [17, 6]<br/>class = LLENA>, fillcolor="#eead7f"] ;
209 -> 210 ;
211 [label=<entropy = 0.961<br/>samples = 13<br/>value = [5, 8]<br/>class = VACIA>, fillcolor="#b5daf5"] ;
209 -> 211 ;
212 [label=<X<SUB>1</SUB> &le; 776.215<br/>entropy = 0.371<br/>samples = 28<br/>value = [2, 26]<br/>class = VACIA>, fillcolor="#48a5e7"] ;
160 -> 212 ;
213 [label=<entropy = 0.0<br/>samples = 24<br/>value = [0, 24]<br/>class = VACIA>, fillcolor="#399de5"] ;
212 -> 213 ;
214 [label=<X<SUB>9</SUB> &le; 4116.0<br/>entropy = 1.0<br/>samples = 4<br/>value = [2, 2]<br/>class = LLENA>, fillcolor="#ffffff"] ;
212 -> 214 ;
215 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = VACIA>, fillcolor="#399de5"] ;
214 -> 215 ;
216 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = LLENA>, fillcolor="#e58139"] ;
214 -> 216 ;
}
